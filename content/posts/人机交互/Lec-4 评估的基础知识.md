---
title: "Lec-4 评估的基础知识"
date: 2024-11-25T14:28:54-08:00
categories: 
- "人机交互"
featureimage: https://runzblog.oss-cn-hangzhou.aliyuncs.com/universal/background1.jpg
summary: "--- --- “范型”与“技术”： 1. 范型与具体学科相关，对如何评估有很大影响：可用性测试是一种评估范型 2. 每种范型有特定的技术：可用性测试的技术有观察、问卷调查、访谈等 设计人员非正式地向..."
---

## 背景

- 评估是设计过程的组成部分

### 评估

- 评估是系统化的数据搜集过程
- 用户在与原型、应用程序等交互时收集关于**用户体验**方面的信息，从而改进其设计
- 评估侧重系统的**可用性**和**用户体验**
- 目的不是设法理解用户，而是评估特定用户在一个特定的环境背景中*如何使用一个系统来执行一个特定的任务*

## 评估的四 W

- `Why`：肯定是要设计一个好的交互系统呀
- `What`：交互系统的可用性和用户体验
- `Where`：取决于评估的对象
- `When`：取决于产品类型。可以在研发前，也可以在完成产品后。

---

## 评估原则

- 评估应当依赖产品的用户
- 评估与设计应当结合进行
- 评估应该在用户的实际工作任务和操作环境下进行
- 评估要选择有广泛代表性的用户

---


## 评估范型
“范型”与“技术”：

1. 范型与具体学科相关，对如何评估有很大影响：可用性测试是一种评估范型
2. 每种范型有特定的技术：可用性测试的技术有观察、问卷调查、访谈等
### 快速评估

设计人员非正式地向用户或顾问了解反馈信息，以证实设计构思是否符合用户需要。

**基本特征**：快速

- 可在任何阶段进行
- 强调 “快速了解”，而非仔细记录研究发现
- 得到的数据通常是非正式、叙述性的
- 是设计网站时常用的方法

### 可用性测试

**基本特征**：在评估人员的密切控制之下实行

- 评测典型用户执行典型任务时的情况。并进行量化
- 缺点：测试用户的数量通常较少、不适合进行细致的统计分析

### 实地研究

理解用户的实际工作情形以及技术对他们的影响。

**基本特征**：在自然工作环境中进行

- 探索新技术的应用契机
- 确定产品的需求
- 促进技术的引入
- 评估技术的应用

难点：
- 如何不对受试者造成影响
- 控制权在用户，很难预测即将发生和出现的情况

### 预测性评估

研究人员通过想象或对界面的使用过程进行建模。

**基本特征**：用户可以不在场；快速成本低

- 专家们根据自己对典型用户的了解预测可用性问题的可用性评估
- 逐步通过场景或基于问题回答的走查法
- 用于比较相同应用不同界面的原型法，如使用Fitts定律预测使用设备定位目标的时间

## 评估技术
似乎今年 PPT 上没有。但是这肯定**很重要**，毕竟下列评估方法就是后面几节讲的内容。

#### 内容

-  观察用户
-  询问用户意见
-  询问专家意见
-  用户测试
-  基于模型和理论评估

#### 区分评估技术的因素

1. 评估在周期中的位置：设计早期阶段的评估更快速、便宜
2. 评估的形式：实验室环境 or 工作环境
3. 技术的主客观程度
    1. 技术越主观，受评估人员知识的影响越大，如认知走查等
4. 测量的类型：与技术的主客观性有关
    1. 主观技术：定性数据
    2. 客观技术：定量数据
5. 提供的信息
    1. 低层信息：这个图标是可理解的吗？
    2. 高层信息：这个系统是可用的吗？
6. 响应的及时性
    1. 边做边说法可及时记录用户行为
    2. 任务后的走查取决于对事件的回忆
7. 干扰程度：直接响应测量可能会影响用户表现
8. 所需资源：设备、时间、资金、参与者、评估人员的专业技术及环境等
---
## 评估方法组合

评估方法的组合取决于项目待评估的具体特性。

- 常用组合
    1. 启发式评估+边做边说等用户测试技术
        1. 专家可通过启发性评估排除显而易见的可用性问题
        2. 重新设计后，经用户测试，反复检查设计的效果
    2. 访谈+问卷调查
        1. 先对小部分用户进行访谈，确定问卷中的具体问题
- 启发式评估 vs.用户测试
    1. 前者不需要用户参与
    2. 二者发现的可用性问题不同，可以互补

---

## 人机交互的实证研究方法

WTF，这会考吗
