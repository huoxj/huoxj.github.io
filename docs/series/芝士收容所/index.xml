<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>芝士收容所 on Runz&#39;s Blog</title>
    <link>https://huoxj.github.io/series/%E8%8A%9D%E5%A3%AB%E6%94%B6%E5%AE%B9%E6%89%80/</link>
    <description>Recent content in 芝士收容所 on Runz&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>cn</language>
    <lastBuildDate>Mon, 27 Jan 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://huoxj.github.io/series/%E8%8A%9D%E5%A3%AB%E6%94%B6%E5%AE%B9%E6%89%80/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>读论文-Vectorized Batch PIR</title>
      <link>https://huoxj.github.io/posts/%E8%8A%9D%E5%A3%AB%E6%94%B6%E5%AE%B9%E6%89%80/%E8%AF%BB%E8%AE%BA%E6%96%87-vectorized-batch-pir/</link>
      <pubDate>Mon, 27 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://huoxj.github.io/posts/%E8%8A%9D%E5%A3%AB%E6%94%B6%E5%AE%B9%E6%89%80/%E8%AF%BB%E8%AE%BA%E6%96%87-vectorized-batch-pir/</guid>
      <description>&lt;p&gt;传统的 PIR (Private Information Retrieval) 里，客户端一次 PIR 只会请求数据库中的一个项。但在实际使用中，客户端往往会请求多个项，但为每一个项都单独调用一次 PIR 显然不够并行，而且会暴露用户请求的次数，所以诞生了 Batch PIR。这篇论文提出了一个基于向量化优化的 Batch PIR。相较传统的 Batch PIR，沟通开销有 7.5x ~ 98.5x 的提升。&lt;/p&gt;&#xA;&lt;h2 id=&#34;前置知识&#34;&gt;前置知识&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Somewhat Homomorphic Encryption&lt;/li&gt;&#xA;&lt;li&gt;Vectorized Homomorphic Encryption&lt;/li&gt;&#xA;&lt;li&gt;Noise Growth and Computation Cost of SHE Operations&lt;/li&gt;&#xA;&lt;li&gt;PIR and Batch PIR&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;previous-batch-pir&#34;&gt;Previous Batch PIR&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Angel 等人的传统 PIR 方法&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://runzblog.oss-cn-hangzhou.aliyuncs.com/postimg/202501271758248.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;以论文里的图为例：&lt;/p&gt;&#xA;&lt;p&gt;在所有请求发生之前，server 需要初始化 $w$ 个哈希函数 $h$（图中 $w=3$ 个）。然后将数据库中的每一项的项数编号，分布通过这几个函数来映射到 $w$ 个桶里。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;桶的大小一般取 $B=1.5b$，其中 $b$ 是客户端请求 batch 的宽度。图中 $b=3, B=5$&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;客户端发起请求，目标是生成一个宽度为 $B$ 的请求向量。对客户端请求的 batch 中的每一项，依次尝试使用那几个哈希函数来映射到桶里，只要有一个能映射到空桶（图中用 $\perp$ 表示），就把这一项放进去。&lt;/p&gt;</description>
    </item>
    <item>
      <title>读论文-一种私有信息检索在GPU上的高效实现</title>
      <link>https://huoxj.github.io/posts/%E8%8A%9D%E5%A3%AB%E6%94%B6%E5%AE%B9%E6%89%80/%E8%AF%BB%E8%AE%BA%E6%96%87-%E4%B8%80%E7%A7%8D%E7%A7%81%E6%9C%89%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%9C%A8gpu%E4%B8%8A%E7%9A%84%E9%AB%98%E6%95%88%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Wed, 22 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://huoxj.github.io/posts/%E8%8A%9D%E5%A3%AB%E6%94%B6%E5%AE%B9%E6%89%80/%E8%AF%BB%E8%AE%BA%E6%96%87-%E4%B8%80%E7%A7%8D%E7%A7%81%E6%9C%89%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E5%9C%A8gpu%E4%B8%8A%E7%9A%84%E9%AB%98%E6%95%88%E5%AE%9E%E7%8E%B0/</guid>
      <description>&lt;p&gt;原文 title：GPU-Based PIR for On-device ML Inference&lt;/p&gt;&#xA;&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;On-device ML Inference 的 device 有计算与存储限制&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;在推荐等场景下，ML 推理需要查 Embedding table&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Embedding table 相当大，不得不存在云端&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;用户直接查表，可能会泄露用户隐私&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;使用 naive DPF-PIR 查表&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;通信成本高，表有多长就得传多大的向量&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;计算成本高，加密次数多&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;优化-dpf-pir&#34;&gt;优化 DPF-PIR&lt;/h2&gt;&#xA;&lt;h3 id=&#34;建模&#34;&gt;建模&lt;/h3&gt;&#xA;&lt;p&gt;DPF-PIR 在单次查询中，主要有三个步骤：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;(client) 生成(gen)密钥&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;(server) 评估(eval)密钥，得到秘密分享 secret share&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;(server) 计算秘密分享与 Embedding table 矩阵的积，返回给 client&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;其中，gen 步骤不是瓶颈，目前不需要优化。&lt;/p&gt;&#xA;&lt;p&gt;多个查询之间是独立的，使用 Batch 优化。&lt;/p&gt;&#xA;&lt;h3 id=&#34;eval-的-gpu-优化&#34;&gt;eval 的 GPU 优化&lt;/h3&gt;&#xA;&lt;p&gt;论文里选择了引用 [32] 描述的 DPF 算法。本质上是一个动态规划/dfs。&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;我觉得选择这个 DPF 算法的原因主要是考虑了通信开销。开销是随着 Embedding table 的大小对数增长的。&lt;/p&gt;&#xA;&lt;p&gt;只是文章里没细说，也没有列举其他的算法并进行对比。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;递推公式只取和优化相关的部分，大致长这样：&lt;/p&gt;&#xA;&lt;p&gt;$$&lt;br&gt;&#xA;P(d,j)=f(P(d-1,\lfloor j/2\rfloor))&lt;br&gt;&#xA;$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>读论文-YOLO v1</title>
      <link>https://huoxj.github.io/posts/%E8%8A%9D%E5%A3%AB%E6%94%B6%E5%AE%B9%E6%89%80/%E8%AF%BB%E8%AE%BA%E6%96%87-yolo-v1/</link>
      <pubDate>Fri, 08 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://huoxj.github.io/posts/%E8%8A%9D%E5%A3%AB%E6%94%B6%E5%AE%B9%E6%89%80/%E8%AF%BB%E8%AE%BA%E6%96%87-yolo-v1/</guid>
      <description>&lt;p&gt;大创要做一个基于两个特征矩阵的信号分割与分类（不知道该不该这么描述），精确度要求不高，但对实时性要求比较高。我想到了借鉴 YOLO 来解决这个问题，所以顺便就来读一下 YOLO 初代的论文，太复杂了猪脑是理解不能的。&lt;/p&gt;&#xA;&lt;h2 id=&#34;skimming&#34;&gt;Skimming&lt;/h2&gt;&#xA;&lt;h3 id=&#34;摘要&#34;&gt;摘要&lt;/h3&gt;&#xA;&lt;p&gt;YOLO 做的活是 object detection。有如下特点：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;单 CNN 实现图像分割与分类，而不是两个阶段两个网络&lt;/li&gt;&#xA;&lt;li&gt;推理快，能做到实时 45 fps 以上&lt;/li&gt;&#xA;&lt;li&gt;比传统的 DPM 和 R-CNN 泛化性更好，准确性也是其他模型的大约两倍&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;佬就是佬，不需要什么花里胡哨的背景介绍，上来就是我们的模型吊打其他模型。&lt;/p&gt;&#xA;&lt;h3 id=&#34;介绍&#34;&gt;介绍&lt;/h3&gt;&#xA;&lt;p&gt;首先，YOLO 的推理过程和人眼很像。这应该是在暗示模型的名字由来（&lt;/p&gt;&#xA;&lt;p&gt;然后三大点：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;YOLO 很快。&lt;/li&gt;&#xA;&lt;li&gt;YOLO 视野更广。推理图片是依靠图像全局信息，而不是滑动窗口那种局部信息。&lt;/li&gt;&#xA;&lt;li&gt;YOLO 泛化很强。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;原理&#34;&gt;原理&lt;/h3&gt;&#xA;&lt;p&gt;这里得好好看，所以先跳过。&lt;/p&gt;&#xA;&lt;h3 id=&#34;对比其他网络&#34;&gt;对比其他网络&lt;/h3&gt;&#xA;&lt;p&gt;对比了 DPM 和 R-CNN 等模型。除了这两个模型稍微认识以外，其他的都认不得。&lt;/p&gt;&#xA;&lt;p&gt;反正很强。&lt;/p&gt;&#xA;&lt;h2 id=&#34;原理-1&#34;&gt;原理&lt;/h2&gt;&#xA;&lt;h3 id=&#34;one-stage-如何实现&#34;&gt;One-stage 如何实现&lt;/h3&gt;&#xA;&lt;p&gt;YOLO 将一张图像分成了 $S$ 行 $S$ 列块方格。&lt;/p&gt;&#xA;&lt;p&gt;每一块方格负责预测：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;物体类别&lt;/li&gt;&#xA;&lt;li&gt;$B$ 个预测框 (Bounding box)，以及对应置信度&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;参考下方图片。&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://runzblog.oss-cn-hangzhou.aliyuncs.com/postimg/202411101019480.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.cnblogs.com/xiaoxiaojiea/p/14534513.html&#34;&gt;目标检测入门论文YOLOV1精读以及pytorch源码复现(yolov1) - 小小猿笔记 - 博客园&lt;/a&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
