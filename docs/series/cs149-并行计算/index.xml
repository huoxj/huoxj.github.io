<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CS149-并行计算 on Runz&#39;s Blog</title>
    <link>https://huoxj.github.io/series/cs149-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/</link>
    <description>Recent content in CS149-并行计算 on Runz&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>cn</language>
    <lastBuildDate>Mon, 17 Feb 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://huoxj.github.io/series/cs149-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Asst3</title>
      <link>https://huoxj.github.io/posts/cs149-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/asst3/</link>
      <pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://huoxj.github.io/posts/cs149-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/asst3/</guid>
      <description>&lt;h2 id=&#34;part-1-saxpy&#34;&gt;Part 1: SAXPY&lt;/h2&gt;&#xA;&lt;p&gt;使用 CUDA 实现 SAXPY。&lt;/p&gt;&#xA;&lt;p&gt;实现很简单，跟着实验文档和 CUDA 文档做下来就行。&lt;/p&gt;&#xA;&lt;p&gt;Question 2：为什么观测到的带宽约为 5.3 GB/s，远不及 PCIe 3.0 的理论带宽上限？&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;主板芯片组性能限制&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pinned memory&lt;/strong&gt; 机制&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GPU 通过 DMA 访存&lt;/li&gt;&#xA;&lt;li&gt;Pinned memory 是物理内存上一块固定的区域，不会被换出，能通过 DMA 加速通信&lt;/li&gt;&#xA;&lt;li&gt;CPU 内存(host data)上的数据是虚拟内存上的可分页数据，可能存在于物理内存上或者硬盘上（页被换出物理内存了）&lt;/li&gt;&#xA;&lt;li&gt;GPU 直接通过物理地址访存，host data 需要先拷贝到临时的 pinned memory 区上，再拷贝到 GPU (device memory)&lt;/li&gt;&#xA;&lt;li&gt;用 &lt;code&gt;cudaHostAlloc&lt;/code&gt; 或 &lt;code&gt;cudaMallocHost&lt;/code&gt; 分配 pinned memory&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/whiteBear/p/17842246.html&#34;&gt;CUDA:页锁定内存(pinned memory)和按页分配内存(pageable memory ) - 牛犁heart - 博客园&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;part-2&#34;&gt;Part 2&lt;/h2&gt;&#xA;&lt;h3 id=&#34;parallel-prefix-sum&#34;&gt;Parallel Prefix-Sum&lt;/h3&gt;&#xA;&lt;p&gt;使用 CUDA 实现一个并行的前缀和算法。&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/91089093&#34;&gt;并行算法科普向 系列之二：前缀和，fork-join 和矩阵乘法 - 知乎&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Asst1</title>
      <link>https://huoxj.github.io/posts/cs149-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/asst1/</link>
      <pubDate>Fri, 08 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://huoxj.github.io/posts/cs149-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/asst1/</guid>
      <description>&lt;h2 id=&#34;prog1-mandelbrot_threads&#34;&gt;Prog1-mandelbrot_threads&lt;/h2&gt;&#xA;&lt;p&gt;使用 &lt;code&gt;std::thread&lt;/code&gt; 来绘制分形图像。&lt;/p&gt;&#xA;&lt;h3 id=&#34;默认策略&#34;&gt;默认策略&lt;/h3&gt;&#xA;&lt;p&gt;默认策略是将图像分成高度相同的几块，每一块分给一个线程画。&lt;/p&gt;&#xA;&lt;p&gt;这样其实做不到负载均衡，因为每一块画的工作量是不同的。&lt;/p&gt;&#xA;&lt;p&gt;特别是 view1，很明显发现画中间部分的线程工作时间远高于两边的线程。&#xA;&lt;img src=&#34;https://runzblog.oss-cn-hangzhou.aliyuncs.com/postimg/202411080945106.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;代码实现很朴实，均分然后画就好了。&lt;/p&gt;&#xA;&lt;p&gt;在 R7 5800x上（原生 8 核心 16 线程），画 view1：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;8 线程倍率：4.04x&lt;/li&gt;&#xA;&lt;li&gt;16线程倍率：7.55x&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;都被 view1 中的画中间部分的线程拖后腿了。&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#d8dee9;background-color:#2e3440;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#81a1c1&#34;&gt;int&lt;/span&gt; startRow &lt;span style=&#34;color:#81a1c1&#34;&gt;=&lt;/span&gt; args&lt;span style=&#34;color:#81a1c1&#34;&gt;-&amp;gt;&lt;/span&gt;height &lt;span style=&#34;color:#81a1c1&#34;&gt;/&lt;/span&gt; args&lt;span style=&#34;color:#81a1c1&#34;&gt;-&amp;gt;&lt;/span&gt;numThreads &lt;span style=&#34;color:#81a1c1&#34;&gt;*&lt;/span&gt; args&lt;span style=&#34;color:#81a1c1&#34;&gt;-&amp;gt;&lt;/span&gt;threadId&lt;span style=&#34;color:#eceff4&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    numRows &lt;span style=&#34;color:#81a1c1&#34;&gt;=&lt;/span&gt; args&lt;span style=&#34;color:#81a1c1&#34;&gt;-&amp;gt;&lt;/span&gt;height &lt;span style=&#34;color:#81a1c1&#34;&gt;/&lt;/span&gt; args&lt;span style=&#34;color:#81a1c1&#34;&gt;-&amp;gt;&lt;/span&gt;numThreads&lt;span style=&#34;color:#eceff4&#34;&gt;;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;mandelbrotSerial&lt;span style=&#34;color:#eceff4&#34;&gt;(&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;args&lt;span style=&#34;color:#81a1c1&#34;&gt;-&amp;gt;&lt;/span&gt;x0&lt;span style=&#34;color:#eceff4&#34;&gt;,&lt;/span&gt; args&lt;span style=&#34;color:#81a1c1&#34;&gt;-&amp;gt;&lt;/span&gt;y0&lt;span style=&#34;color:#eceff4&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;args&lt;span style=&#34;color:#81a1c1&#34;&gt;-&amp;gt;&lt;/span&gt;x1&lt;span style=&#34;color:#eceff4&#34;&gt;,&lt;/span&gt; args&lt;span style=&#34;color:#81a1c1&#34;&gt;-&amp;gt;&lt;/span&gt;y1&lt;span style=&#34;color:#eceff4&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;args&lt;span style=&#34;color:#81a1c1&#34;&gt;-&amp;gt;&lt;/span&gt;width&lt;span style=&#34;color:#eceff4&#34;&gt;,&lt;/span&gt; args&lt;span style=&#34;color:#81a1c1&#34;&gt;-&amp;gt;&lt;/span&gt;height&lt;span style=&#34;color:#eceff4&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;startRow&lt;span style=&#34;color:#eceff4&#34;&gt;,&lt;/span&gt; numRows&lt;span style=&#34;color:#eceff4&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;args&lt;span style=&#34;color:#81a1c1&#34;&gt;-&amp;gt;&lt;/span&gt;maxIterations&lt;span style=&#34;color:#eceff4&#34;&gt;,&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;args&lt;span style=&#34;color:#81a1c1&#34;&gt;-&amp;gt;&lt;/span&gt;output&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#x9;&lt;span style=&#34;color:#eceff4&#34;&gt;);&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;均衡策略&#34;&gt;均衡策略&lt;/h3&gt;&#xA;&lt;p&gt;让线程按行交错绘制图像。&lt;/p&gt;&#xA;&lt;p&gt;其实这个策略是在模拟随机分配任务。思想是将任务分成尽可能小的部分，然后让大家随机挑任务做。&lt;/p&gt;&#xA;&lt;p&gt;可以证明对长度为 $n$ 的数列 $a$（工作量），在其中随机取 $n/s$ 项（$s$就是线程数），其和的期望是相同的。&lt;/p&gt;&#xA;&lt;p&gt;代码实现是按行交错绘制，实现起来比较简单。&lt;/p&gt;&#xA;&lt;p&gt;对于 view1：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;8 线程：7.53x&lt;/li&gt;&#xA;&lt;li&gt;16 线程： 11.48x&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;16线程反而缩水得很严重，主要原因应该是 8 线程时每个线程独享一个核心，基本做到了并行。但是 16 线程时就是两个线程争抢一个核心了，需要并发。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
